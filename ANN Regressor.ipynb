{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6c44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7965d8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AT      V       AP     RH      PE\n",
       "0  14.96  41.76  1024.07  73.17  463.26\n",
       "1  25.18  62.96  1020.04  59.08  444.37\n",
       "2   5.11  39.40  1012.16  92.14  488.56\n",
       "3  20.86  57.32  1010.24  76.64  446.48\n",
       "4  10.82  37.50  1009.23  96.62  473.90"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('D:\\\\self study\\\\Naresh IT\\\\Data Science\\\\21. ANN\\\\energy.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab59c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9568 entries, 0 to 9567\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      9568 non-null   float64\n",
      " 1   V       9568 non-null   float64\n",
      " 2   AP      9568 non-null   float64\n",
      " 3   RH      9568 non-null   float64\n",
      " 4   PE      9568 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 373.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67e5173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  14.96,   41.76, 1024.07,   73.17],\n",
       "       [  25.18,   62.96, 1020.04,   59.08],\n",
       "       [   5.11,   39.4 , 1012.16,   92.14],\n",
       "       ...,\n",
       "       [  31.32,   74.33, 1012.92,   36.48],\n",
       "       [  24.48,   69.45, 1013.86,   62.39],\n",
       "       [  21.6 ,   62.52, 1017.23,   67.87]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= df.iloc[:,:-1].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c251a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([463.26, 444.37, 488.56, ..., 429.57, 435.74, 453.28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= df.iloc[:,-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c9c443",
   "metadata": {},
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d1df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24865fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7654, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1783af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a5c3885",
   "metadata": {},
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "516bb2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8097ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e73bde5",
   "metadata": {},
   "source": [
    "## adding input layers and first hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3471a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb9768bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(Dense(input_dim= 4, units= 6, kernel_initializer= 'uniform',activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5306ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(Dense(units= 6,activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50076589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "781f5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(Dense(units = 6, activation = 'relu'))\n",
    "\n",
    "# adding output layer\n",
    "ann.add(Dense(units = 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1978ee0e",
   "metadata": {},
   "source": [
    "# compailing ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a52b7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785748b5",
   "metadata": {},
   "source": [
    "# training the Ann on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5fe98fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "240/240 [==============================] - 1s 1ms/step - loss: 123048.6094\n",
      "Epoch 2/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 438.8243\n",
      "Epoch 3/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 411.4601\n",
      "Epoch 4/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 384.5864\n",
      "Epoch 5/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 352.7959\n",
      "Epoch 6/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 318.9488\n",
      "Epoch 7/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 284.2175\n",
      "Epoch 8/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 249.0301\n",
      "Epoch 9/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 213.9986\n",
      "Epoch 10/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 180.6882\n",
      "Epoch 11/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 149.9986\n",
      "Epoch 12/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 123.0028\n",
      "Epoch 13/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 100.5925\n",
      "Epoch 14/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 82.6424\n",
      "Epoch 15/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 68.3865\n",
      "Epoch 16/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 58.3670\n",
      "Epoch 17/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 50.5101\n",
      "Epoch 18/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 44.7728\n",
      "Epoch 19/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 40.0236\n",
      "Epoch 20/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 36.4544\n",
      "Epoch 21/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 34.2955\n",
      "Epoch 22/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 32.1678\n",
      "Epoch 23/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 31.1045\n",
      "Epoch 24/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 30.2078\n",
      "Epoch 25/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 29.7190\n",
      "Epoch 26/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 29.3350\n",
      "Epoch 27/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 29.6538\n",
      "Epoch 28/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.4694\n",
      "Epoch 29/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.1512\n",
      "Epoch 30/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.2808\n",
      "Epoch 31/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.0321\n",
      "Epoch 32/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.3312\n",
      "Epoch 33/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 27.5036\n",
      "Epoch 34/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1350\n",
      "Epoch 35/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1302\n",
      "Epoch 36/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4454\n",
      "Epoch 37/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4999\n",
      "Epoch 38/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4274\n",
      "Epoch 39/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.2539\n",
      "Epoch 40/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.3668\n",
      "Epoch 41/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.9401\n",
      "Epoch 42/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7696\n",
      "Epoch 43/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.8167\n",
      "Epoch 44/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.9492\n",
      "Epoch 45/100\n",
      "240/240 [==============================] - 0s 993us/step - loss: 26.8687\n",
      "Epoch 46/100\n",
      "240/240 [==============================] - 0s 988us/step - loss: 26.5556\n",
      "Epoch 47/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.0571\n",
      "Epoch 48/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1561\n",
      "Epoch 49/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.0403\n",
      "Epoch 50/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7604\n",
      "Epoch 51/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.4613\n",
      "Epoch 52/100\n",
      "240/240 [==============================] - 0s 959us/step - loss: 27.3338\n",
      "Epoch 53/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6744\n",
      "Epoch 54/100\n",
      "240/240 [==============================] - 0s 974us/step - loss: 28.2717\n",
      "Epoch 55/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.2620\n",
      "Epoch 56/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7989\n",
      "Epoch 57/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4809\n",
      "Epoch 58/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.9521\n",
      "Epoch 59/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.3944\n",
      "Epoch 60/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.9561\n",
      "Epoch 61/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.3199\n",
      "Epoch 62/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4361\n",
      "Epoch 63/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1239\n",
      "Epoch 64/100\n",
      "240/240 [==============================] - 0s 990us/step - loss: 26.5923\n",
      "Epoch 65/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7465\n",
      "Epoch 66/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.8256\n",
      "Epoch 67/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.6746\n",
      "Epoch 68/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.5642\n",
      "Epoch 69/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1788\n",
      "Epoch 70/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6834\n",
      "Epoch 71/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7954\n",
      "Epoch 72/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.2788\n",
      "Epoch 73/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7670\n",
      "Epoch 74/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 27.6598\n",
      "Epoch 75/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1083\n",
      "Epoch 76/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.5417\n",
      "Epoch 77/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.4905\n",
      "Epoch 78/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.9637\n",
      "Epoch 79/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.9100\n",
      "Epoch 80/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7832\n",
      "Epoch 81/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.8588\n",
      "Epoch 82/100\n",
      "240/240 [==============================] - 0s 927us/step - loss: 27.2393\n",
      "Epoch 83/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.8651\n",
      "Epoch 84/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.9523\n",
      "Epoch 85/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7786\n",
      "Epoch 86/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.2196\n",
      "Epoch 87/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6812\n",
      "Epoch 88/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.5243\n",
      "Epoch 89/100\n",
      "240/240 [==============================] - 0s 987us/step - loss: 27.2432\n",
      "Epoch 90/100\n",
      "240/240 [==============================] - 0s 989us/step - loss: 27.0667\n",
      "Epoch 91/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7726\n",
      "Epoch 92/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.2245\n",
      "Epoch 93/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.2968\n",
      "Epoch 94/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1376\n",
      "Epoch 95/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6262\n",
      "Epoch 96/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.9254\n",
      "Epoch 97/100\n",
      "240/240 [==============================] - 0s 985us/step - loss: 27.2154\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 1ms/step - loss: 27.2583\n",
      "Epoch 99/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.0634\n",
      "Epoch 100/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.8407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2930ed76d30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train,y_train,epochs =100,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56bb6ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([473.93, 467.87, 431.97, ..., 459.01, 462.72, 428.12])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765e17d2",
   "metadata": {},
   "source": [
    "# prediction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d34150ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 738us/step\n",
      "60/60 [==============================] - 0s 528us/step\n"
     ]
    }
   ],
   "source": [
    "train_prediction = ann.predict(X_train)\n",
    "test_prediction = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e025273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[472.61835],\n",
       "       [465.34155],\n",
       "       [429.1474 ],\n",
       "       ...,\n",
       "       [465.62387],\n",
       "       [472.5961 ],\n",
       "       [429.24893]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93999ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[431.26715],\n",
       "       [462.22678],\n",
       "       [465.72406],\n",
       "       ...,\n",
       "       [472.95474],\n",
       "       [439.73407],\n",
       "       [458.9416 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5c31280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9116969948222688"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score_train=r2_score(y_train,train_prediction)\n",
    "r2_score_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06c71812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9160668658485542"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score_test=r2_score(y_test,test_prediction)\n",
    "r2_score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba6428d",
   "metadata": {},
   "source": [
    "# cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e335e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_cross_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(input_dim= 4,units=6,kernel_initializer= 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units=6,kernel_initializer= 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units=1,kernel_initializer= 'uniform', activation = 'relu'))\n",
    "    classifier.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')   \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04e57bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14eca568",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasRegressor(built_cross_classifier, batch_size = 10,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d465ba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([463.26, 444.37, 488.56, ..., 429.57, 435.74, 453.28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d910189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "766/766 [==============================] - 1s 815us/step - loss: 206589.1094\n",
      "Epoch 2/50\n",
      "766/766 [==============================] - 1s 842us/step - loss: 206589.1094\n",
      "Epoch 3/50\n",
      "766/766 [==============================] - 1s 863us/step - loss: 206589.1562\n",
      "Epoch 4/50\n",
      "766/766 [==============================] - 1s 893us/step - loss: 206589.4062\n",
      "Epoch 5/50\n",
      "766/766 [==============================] - 1s 875us/step - loss: 206589.2031\n",
      "Epoch 6/50\n",
      "766/766 [==============================] - 1s 866us/step - loss: 206589.2031\n",
      "Epoch 7/50\n",
      "766/766 [==============================] - 1s 928us/step - loss: 206589.1719\n",
      "Epoch 8/50\n",
      "766/766 [==============================] - 1s 904us/step - loss: 206588.8750\n",
      "Epoch 9/50\n",
      "766/766 [==============================] - 1s 872us/step - loss: 206588.9531\n",
      "Epoch 10/50\n",
      "766/766 [==============================] - 1s 875us/step - loss: 206589.2344\n",
      "Epoch 11/50\n",
      "766/766 [==============================] - 1s 896us/step - loss: 206589.0938\n",
      "Epoch 12/50\n",
      "766/766 [==============================] - 1s 883us/step - loss: 206589.0469\n",
      "Epoch 13/50\n",
      "766/766 [==============================] - 1s 876us/step - loss: 206589.1094\n",
      "Epoch 14/50\n",
      "766/766 [==============================] - 1s 877us/step - loss: 206589.1562\n",
      "Epoch 15/50\n",
      "766/766 [==============================] - 1s 876us/step - loss: 206589.2344\n",
      "Epoch 16/50\n",
      "766/766 [==============================] - 1s 836us/step - loss: 206589.2344\n",
      "Epoch 17/50\n",
      "766/766 [==============================] - 1s 858us/step - loss: 206589.1562\n",
      "Epoch 18/50\n",
      "766/766 [==============================] - 1s 946us/step - loss: 206589.1094\n",
      "Epoch 19/50\n",
      "766/766 [==============================] - 1s 927us/step - loss: 206589.1406\n",
      "Epoch 20/50\n",
      "766/766 [==============================] - 1s 876us/step - loss: 206589.1719\n",
      "Epoch 21/50\n",
      "766/766 [==============================] - 1s 874us/step - loss: 206589.0781\n",
      "Epoch 22/50\n",
      "766/766 [==============================] - 1s 865us/step - loss: 206589.2969\n",
      "Epoch 23/50\n",
      "766/766 [==============================] - 1s 891us/step - loss: 206589.1875\n",
      "Epoch 24/50\n",
      "766/766 [==============================] - 1s 805us/step - loss: 206589.2031\n",
      "Epoch 25/50\n",
      "766/766 [==============================] - 1s 944us/step - loss: 206589.0938\n",
      "Epoch 26/50\n",
      "766/766 [==============================] - 1s 1000us/step - loss: 206589.2500\n",
      "Epoch 27/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206589.1562\n",
      "Epoch 28/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206589.2031\n",
      "Epoch 29/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206589.1094\n",
      "Epoch 30/50\n",
      "766/766 [==============================] - 1s 942us/step - loss: 206589.2344\n",
      "Epoch 31/50\n",
      "766/766 [==============================] - 1s 849us/step - loss: 206589.0469\n",
      "Epoch 32/50\n",
      "766/766 [==============================] - 1s 911us/step - loss: 206589.1250\n",
      "Epoch 33/50\n",
      "766/766 [==============================] - 1s 905us/step - loss: 206589.1875\n",
      "Epoch 34/50\n",
      "766/766 [==============================] - 1s 959us/step - loss: 206589.1719\n",
      "Epoch 35/50\n",
      "766/766 [==============================] - 1s 949us/step - loss: 206589.2500\n",
      "Epoch 36/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206589.0625\n",
      "Epoch 37/50\n",
      "766/766 [==============================] - 1s 990us/step - loss: 206589.1250\n",
      "Epoch 38/50\n",
      "766/766 [==============================] - 1s 947us/step - loss: 206589.2031\n",
      "Epoch 39/50\n",
      "766/766 [==============================] - 1s 958us/step - loss: 206589.0938\n",
      "Epoch 40/50\n",
      "766/766 [==============================] - 1s 975us/step - loss: 206589.0938\n",
      "Epoch 41/50\n",
      "766/766 [==============================] - 1s 916us/step - loss: 206589.2031\n",
      "Epoch 42/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206589.1250\n",
      "Epoch 43/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206589.1094\n",
      "Epoch 44/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206589.2188\n",
      "Epoch 45/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206589.2500\n",
      "Epoch 46/50\n",
      "766/766 [==============================] - 1s 834us/step - loss: 206589.1562\n",
      "Epoch 47/50\n",
      "766/766 [==============================] - 1s 964us/step - loss: 206589.0000\n",
      "Epoch 48/50\n",
      "766/766 [==============================] - 1s 970us/step - loss: 206589.1250\n",
      "Epoch 49/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206589.1562\n",
      "Epoch 50/50\n",
      "766/766 [==============================] - 1s 886us/step - loss: 206589.0156\n",
      "192/192 [==============================] - 0s 743us/step\n",
      "Epoch 1/50\n",
      "766/766 [==============================] - 1s 924us/step - loss: 62380.5156\n",
      "Epoch 2/50\n",
      "766/766 [==============================] - 1s 925us/step - loss: 256.4090\n",
      "Epoch 3/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 128.8016\n",
      "Epoch 4/50\n",
      "766/766 [==============================] - 1s 994us/step - loss: 70.1475\n",
      "Epoch 5/50\n",
      "766/766 [==============================] - 1s 987us/step - loss: 48.2768\n",
      "Epoch 6/50\n",
      "766/766 [==============================] - 1s 990us/step - loss: 39.0772\n",
      "Epoch 7/50\n",
      "766/766 [==============================] - 1s 948us/step - loss: 35.4656\n",
      "Epoch 8/50\n",
      "766/766 [==============================] - 1s 925us/step - loss: 33.1338\n",
      "Epoch 9/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 32.5055\n",
      "Epoch 10/50\n",
      "766/766 [==============================] - 1s 968us/step - loss: 31.5817\n",
      "Epoch 11/50\n",
      "766/766 [==============================] - 1s 916us/step - loss: 31.1175\n",
      "Epoch 12/50\n",
      "766/766 [==============================] - 1s 859us/step - loss: 30.9256\n",
      "Epoch 13/50\n",
      "766/766 [==============================] - 1s 821us/step - loss: 30.3160\n",
      "Epoch 14/50\n",
      "766/766 [==============================] - 1s 870us/step - loss: 30.3449\n",
      "Epoch 15/50\n",
      "766/766 [==============================] - 1s 910us/step - loss: 30.0407\n",
      "Epoch 16/50\n",
      "766/766 [==============================] - 1s 855us/step - loss: 30.0153\n",
      "Epoch 17/50\n",
      "766/766 [==============================] - 1s 860us/step - loss: 29.7546\n",
      "Epoch 18/50\n",
      "766/766 [==============================] - 1s 855us/step - loss: 29.7767\n",
      "Epoch 19/50\n",
      "766/766 [==============================] - 1s 868us/step - loss: 29.3520\n",
      "Epoch 20/50\n",
      "766/766 [==============================] - 1s 883us/step - loss: 29.4252\n",
      "Epoch 21/50\n",
      "766/766 [==============================] - 1s 866us/step - loss: 29.2821\n",
      "Epoch 22/50\n",
      "766/766 [==============================] - 1s 911us/step - loss: 29.3271\n",
      "Epoch 23/50\n",
      "766/766 [==============================] - 1s 751us/step - loss: 29.2037\n",
      "Epoch 24/50\n",
      "766/766 [==============================] - 1s 912us/step - loss: 29.0077\n",
      "Epoch 25/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.2290\n",
      "Epoch 26/50\n",
      "766/766 [==============================] - 1s 999us/step - loss: 29.2372\n",
      "Epoch 27/50\n",
      "766/766 [==============================] - 1s 872us/step - loss: 29.2971\n",
      "Epoch 28/50\n",
      "766/766 [==============================] - 1s 806us/step - loss: 29.0333\n",
      "Epoch 29/50\n",
      "766/766 [==============================] - 1s 840us/step - loss: 29.4272\n",
      "Epoch 30/50\n",
      "766/766 [==============================] - 1s 953us/step - loss: 29.2568\n",
      "Epoch 31/50\n",
      "766/766 [==============================] - 1s 974us/step - loss: 28.9004\n",
      "Epoch 32/50\n",
      "766/766 [==============================] - 1s 898us/step - loss: 29.0408\n",
      "Epoch 33/50\n",
      "766/766 [==============================] - 1s 781us/step - loss: 29.0840\n",
      "Epoch 34/50\n",
      "766/766 [==============================] - 1s 854us/step - loss: 29.2023\n",
      "Epoch 35/50\n",
      "766/766 [==============================] - 1s 876us/step - loss: 29.2181\n",
      "Epoch 36/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.2970\n",
      "Epoch 37/50\n",
      "766/766 [==============================] - 1s 979us/step - loss: 29.1485\n",
      "Epoch 38/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.2554\n",
      "Epoch 39/50\n",
      "766/766 [==============================] - 1s 944us/step - loss: 29.0550\n",
      "Epoch 40/50\n",
      "766/766 [==============================] - 1s 894us/step - loss: 28.9743\n",
      "Epoch 41/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.0396\n",
      "Epoch 42/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 28.6663\n",
      "Epoch 43/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 28.9089\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 1s 1ms/step - loss: 28.7501\n",
      "Epoch 45/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 28.9838\n",
      "Epoch 46/50\n",
      "766/766 [==============================] - 1s 861us/step - loss: 29.0370\n",
      "Epoch 47/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.0028\n",
      "Epoch 48/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.3182\n",
      "Epoch 49/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 28.9811\n",
      "Epoch 50/50\n",
      "766/766 [==============================] - 1s 913us/step - loss: 28.8720\n",
      "192/192 [==============================] - 0s 654us/step\n",
      "Epoch 1/50\n",
      "766/766 [==============================] - 1s 846us/step - loss: 55157.6953\n",
      "Epoch 2/50\n",
      "766/766 [==============================] - 1s 875us/step - loss: 210.4251\n",
      "Epoch 3/50\n",
      "766/766 [==============================] - 1s 863us/step - loss: 92.5810\n",
      "Epoch 4/50\n",
      "766/766 [==============================] - 1s 850us/step - loss: 53.8895\n",
      "Epoch 5/50\n",
      "766/766 [==============================] - 1s 883us/step - loss: 41.1027\n",
      "Epoch 6/50\n",
      "766/766 [==============================] - 1s 993us/step - loss: 36.0632\n",
      "Epoch 7/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 34.4002\n",
      "Epoch 8/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 33.2028\n",
      "Epoch 9/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 32.4611\n",
      "Epoch 10/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 31.9091\n",
      "Epoch 11/50\n",
      "766/766 [==============================] - 1s 972us/step - loss: 31.5219\n",
      "Epoch 12/50\n",
      "766/766 [==============================] - 1s 887us/step - loss: 31.2117\n",
      "Epoch 13/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.7869\n",
      "Epoch 14/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.8225\n",
      "Epoch 15/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.9594\n",
      "Epoch 16/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.7599\n",
      "Epoch 17/50\n",
      "766/766 [==============================] - 1s 935us/step - loss: 30.1478\n",
      "Epoch 18/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.8304\n",
      "Epoch 19/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.1901\n",
      "Epoch 20/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.9776\n",
      "Epoch 21/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.1690\n",
      "Epoch 22/50\n",
      "766/766 [==============================] - 1s 945us/step - loss: 30.1914\n",
      "Epoch 23/50\n",
      "766/766 [==============================] - 1s 783us/step - loss: 30.1694\n",
      "Epoch 24/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.0184\n",
      "Epoch 25/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.3261\n",
      "Epoch 26/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.9225\n",
      "Epoch 27/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.1988\n",
      "Epoch 28/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.1116\n",
      "Epoch 29/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.3397\n",
      "Epoch 30/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.9686\n",
      "Epoch 31/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.1052\n",
      "Epoch 32/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.0640\n",
      "Epoch 33/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.8324\n",
      "Epoch 34/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.1021\n",
      "Epoch 35/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.0134\n",
      "Epoch 36/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.2630\n",
      "Epoch 37/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.9908\n",
      "Epoch 38/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.0609\n",
      "Epoch 39/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.0648\n",
      "Epoch 40/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.0215\n",
      "Epoch 41/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.1434\n",
      "Epoch 42/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.0755\n",
      "Epoch 43/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.7260\n",
      "Epoch 44/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.8936\n",
      "Epoch 45/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.8854\n",
      "Epoch 46/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.0378\n",
      "Epoch 47/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.8514\n",
      "Epoch 48/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 30.0982\n",
      "Epoch 49/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.7594\n",
      "Epoch 50/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 29.8770\n",
      "192/192 [==============================] - 0s 742us/step\n",
      "Epoch 1/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.4062\n",
      "Epoch 2/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.4062\n",
      "Epoch 3/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3281\n",
      "Epoch 4/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.5312\n",
      "Epoch 5/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.2656\n",
      "Epoch 6/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3750\n",
      "Epoch 7/50\n",
      "766/766 [==============================] - 1s 975us/step - loss: 206734.3594\n",
      "Epoch 8/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3594\n",
      "Epoch 9/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3906\n",
      "Epoch 10/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3594\n",
      "Epoch 11/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3906\n",
      "Epoch 12/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3906\n",
      "Epoch 13/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3750\n",
      "Epoch 14/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3750\n",
      "Epoch 15/50\n",
      "766/766 [==============================] - 1s 2ms/step - loss: 206734.3125\n",
      "Epoch 16/50\n",
      "766/766 [==============================] - 1s 2ms/step - loss: 206734.4844\n",
      "Epoch 17/50\n",
      "766/766 [==============================] - 1s 2ms/step - loss: 206734.2969\n",
      "Epoch 18/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3125\n",
      "Epoch 19/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3906\n",
      "Epoch 20/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3594\n",
      "Epoch 21/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.4844\n",
      "Epoch 22/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.5469\n",
      "Epoch 23/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3438\n",
      "Epoch 24/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3281\n",
      "Epoch 25/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.4375\n",
      "Epoch 26/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.4844\n",
      "Epoch 27/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3594\n",
      "Epoch 28/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.4688\n",
      "Epoch 29/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.4844\n",
      "Epoch 30/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.5938\n",
      "Epoch 31/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.4062\n",
      "Epoch 32/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3906\n",
      "Epoch 33/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.4688\n",
      "Epoch 34/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.2500\n",
      "Epoch 35/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.4531\n",
      "Epoch 36/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3750\n",
      "Epoch 37/50\n",
      "766/766 [==============================] - 1s 996us/step - loss: 206734.3750\n",
      "Epoch 38/50\n",
      "766/766 [==============================] - 1s 904us/step - loss: 206734.3594\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 1s 924us/step - loss: 206734.3281\n",
      "Epoch 40/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.2656\n",
      "Epoch 41/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3281\n",
      "Epoch 42/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.2969\n",
      "Epoch 43/50\n",
      "766/766 [==============================] - 1s 925us/step - loss: 206734.4844\n",
      "Epoch 44/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.5000\n",
      "Epoch 45/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.3750\n",
      "Epoch 46/50\n",
      "766/766 [==============================] - 1s 981us/step - loss: 206734.2812\n",
      "Epoch 47/50\n",
      "766/766 [==============================] - 1s 924us/step - loss: 206734.3438\n",
      "Epoch 48/50\n",
      "766/766 [==============================] - 1s 927us/step - loss: 206734.2812\n",
      "Epoch 49/50\n",
      "766/766 [==============================] - 1s 924us/step - loss: 206734.3281\n",
      "Epoch 50/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206734.4062\n",
      "192/192 [==============================] - 0s 839us/step\n",
      "Epoch 1/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.3594\n",
      "Epoch 2/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.2500\n",
      "Epoch 3/50\n",
      "766/766 [==============================] - 1s 945us/step - loss: 206811.0781\n",
      "Epoch 4/50\n",
      "766/766 [==============================] - 1s 823us/step - loss: 206811.2812\n",
      "Epoch 5/50\n",
      "766/766 [==============================] - 1s 885us/step - loss: 206811.1094\n",
      "Epoch 6/50\n",
      "766/766 [==============================] - 1s 865us/step - loss: 206811.3438\n",
      "Epoch 7/50\n",
      "766/766 [==============================] - 1s 864us/step - loss: 206811.2031\n",
      "Epoch 8/50\n",
      "766/766 [==============================] - 1s 863us/step - loss: 206811.1875\n",
      "Epoch 9/50\n",
      "766/766 [==============================] - 1s 863us/step - loss: 206811.3281\n",
      "Epoch 10/50\n",
      "766/766 [==============================] - 1s 862us/step - loss: 206811.2812\n",
      "Epoch 11/50\n",
      "766/766 [==============================] - 1s 861us/step - loss: 206811.2031\n",
      "Epoch 12/50\n",
      "766/766 [==============================] - 1s 904us/step - loss: 206811.2656\n",
      "Epoch 13/50\n",
      "766/766 [==============================] - 1s 842us/step - loss: 206811.3750\n",
      "Epoch 14/50\n",
      "766/766 [==============================] - 1s 883us/step - loss: 206811.2031\n",
      "Epoch 15/50\n",
      "766/766 [==============================] - 1s 883us/step - loss: 206811.1406\n",
      "Epoch 16/50\n",
      "766/766 [==============================] - 1s 865us/step - loss: 206811.1250\n",
      "Epoch 17/50\n",
      "766/766 [==============================] - 1s 883us/step - loss: 206811.2969\n",
      "Epoch 18/50\n",
      "766/766 [==============================] - 1s 864us/step - loss: 206811.1406\n",
      "Epoch 19/50\n",
      "766/766 [==============================] - 1s 904us/step - loss: 206811.2344\n",
      "Epoch 20/50\n",
      "766/766 [==============================] - 1s 943us/step - loss: 206811.3594\n",
      "Epoch 21/50\n",
      "766/766 [==============================] - 1s 923us/step - loss: 206811.2812\n",
      "Epoch 22/50\n",
      "766/766 [==============================] - 1s 801us/step - loss: 206811.2344\n",
      "Epoch 23/50\n",
      "766/766 [==============================] - 1s 812us/step - loss: 206811.1406\n",
      "Epoch 24/50\n",
      "766/766 [==============================] - 1s 845us/step - loss: 206811.2031\n",
      "Epoch 25/50\n",
      "766/766 [==============================] - 1s 885us/step - loss: 206811.1875\n",
      "Epoch 26/50\n",
      "766/766 [==============================] - 1s 883us/step - loss: 206811.2344\n",
      "Epoch 27/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.2812\n",
      "Epoch 28/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.2656\n",
      "Epoch 29/50\n",
      "766/766 [==============================] - 1s 873us/step - loss: 206811.3906\n",
      "Epoch 30/50\n",
      "766/766 [==============================] - 1s 2ms/step - loss: 206811.0469\n",
      "Epoch 31/50\n",
      "766/766 [==============================] - 1s 2ms/step - loss: 206811.2656\n",
      "Epoch 32/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.1406\n",
      "Epoch 33/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.2969\n",
      "Epoch 34/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.2812\n",
      "Epoch 35/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.1094\n",
      "Epoch 36/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.1250\n",
      "Epoch 37/50\n",
      "766/766 [==============================] - 1s 970us/step - loss: 206811.1875\n",
      "Epoch 38/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.1875\n",
      "Epoch 39/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.1875\n",
      "Epoch 40/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.3125\n",
      "Epoch 41/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.1250\n",
      "Epoch 42/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.2188\n",
      "Epoch 43/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.1250\n",
      "Epoch 44/50\n",
      "766/766 [==============================] - 1s 998us/step - loss: 206811.1875\n",
      "Epoch 45/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.1875\n",
      "Epoch 46/50\n",
      "766/766 [==============================] - 1s 856us/step - loss: 206811.1562\n",
      "Epoch 47/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.0625\n",
      "Epoch 48/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.2344\n",
      "Epoch 49/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.1250\n",
      "Epoch 50/50\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 206811.2188\n",
      "192/192 [==============================] - 0s 576us/step\n",
      "[-722.57291741    0.85099872    0.91567181 -708.88099976 -714.67644871]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-428.8727390671452"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score= cross_val_score(classifier,X,y,cv = 5)\n",
    "print(score)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040172c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
